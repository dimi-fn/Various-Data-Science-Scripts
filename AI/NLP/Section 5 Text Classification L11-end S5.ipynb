{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Section 5 Text Classification L11-end S5.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOqEpEg+3qEBOT+vspWrCo4"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"0ET6PDt-lAe0","colab_type":"text"},"source":["# Text Classification Project\n","Now we're at the point where we should be able to:\n","* Read in a collection of documents - a *corpus*\n","* Transform text into numerical vector data using a pipeline\n","* Create a classifier\n","* Fit/train the classifier\n","* Test the classifier on new data\n","* Evaluate performance\n","\n","For this project we'll use the Cornell University Movie Review polarity dataset v2.0 obtained from http://www.cs.cornell.edu/people/pabo/movie-review-data/\n","\n","In this exercise we'll try to develop a classification model as we did for the SMSSpamCollection dataset - that is, we'll try to predict the Positive/Negative labels based on text content alone. In an upcoming section we'll apply *Sentiment Analysis* to train models that have a deeper understanding of each review."]},{"cell_type":"markdown","metadata":{"id":"gIGHMQkIlG45","colab_type":"text"},"source":["## Perform imports and load the dataset\n","The dataset contains the text of 2000 movie reviews. 1000 are positive, 1000 are negative, and the text has been preprocessed as a tab-delimited file."]},{"cell_type":"code","metadata":{"id":"l9OUXbNllHD4","colab_type":"code","colab":{}},"source":["import numpy as np\n","import pandas as pd\n","\n","# Code to read csv file into colaboratory:\n","!pip install -U -q PyDrive\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SVWHB1IAlOT5","colab_type":"code","colab":{}},"source":["downloaded = drive.CreateFile({'id':'1q9Yh9GorYkl_xf3O_P4zBbPYBXtTcuWx'}) \n","downloaded.GetContentFile('moviereviews.tsv') \n","\n","df= pd.read_csv(\"moviereviews.tsv\", sep='\\t')\n","\n","df.head()\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JoKwicKjlfMm","colab_type":"code","colab":{}},"source":["df.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sa7YKa8qlhuj","colab_type":"code","colab":{}},"source":["len(df)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9elAE7lAlypr","colab_type":"text"},"source":["### Take a look at a typical review. This one is labeled \"negative\":"]},{"cell_type":"code","metadata":{"id":"5j6ZCUpxmlIY","colab_type":"code","colab":{}},"source":["df['review'][0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EgwoTdE5ly3Y","colab_type":"code","colab":{}},"source":["# Below we are displaying the text as a script which is more readable (not like above)\n","from IPython.display import Markdown, display\n","display(Markdown('> '+df['review'][0]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qe-a-iarl0GR","colab_type":"code","colab":{}},"source":["df.head(1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"p-oLI17umrm0","colab_type":"text"},"source":["## Check for missing values:\n","We have intentionally included records with missing data. Some have NaN values, others have short strings composed of only spaces. This might happen if a reviewer declined to provide a comment with their review. We will show two ways using pandas to identify and remove records containing empty data.\n","* NaN records are efficiently handled with [.isnull()](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.isnull.html) and [.dropna()](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.dropna.html)\n","* Strings that contain only whitespace can be handled with [.isspace()](https://docs.python.org/3/library/stdtypes.html#str.isspace), [.itertuples()](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.itertuples.html), and [.drop()](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.drop.html)\n","\n","### Detect & remove NaN values:"]},{"cell_type":"code","metadata":{"id":"yGmUTsrrmrzW","colab_type":"code","colab":{}},"source":["# Check for the existence of NaN values in a cell:\n","df.isnull().sum()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PKmZktbSmzUW","colab_type":"text"},"source":["35 records show **NaN** (this stands for \"not a number\" and is equivalent to *None*). These are easily removed using the `.dropna()` pandas function.\n","<div class=\"alert alert-info\" style=\"margin: 20px\">CAUTION: By setting inplace=True, we permanently affect the DataFrame currently in memory, and this can't be undone. However, it does *not* affect the original source data. If we needed to, we could always load the original DataFrame from scratch.</div>"]},{"cell_type":"code","metadata":{"id":"SErvJNbymzeQ","colab_type":"code","colab":{}},"source":["df.dropna(inplace=True)\n","\n","len(df)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"B8OIbyUlm3bD","colab_type":"text"},"source":["### Detect & remove empty strings\n","Technically, we're dealing with \"whitespace only\" strings. If the original .tsv file had contained empty strings, pandas **.read_csv()** would have assigned NaN values to those cells by default.\n","\n","In order to detect these strings we need to iterate over each row in the DataFrame. The **.itertuples()** pandas method is a good tool for this as it provides access to every field."]},{"cell_type":"code","metadata":{"id":"FT8lY_KoM8Ws","colab_type":"code","colab":{}},"source":["# example to better understand the below code:\n","\n","mystring= \"hello\"\n","my_empty_string= \" \""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PKmNTTNlNEtH","colab_type":"code","colab":{}},"source":["mystring.isspace()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YRhMqzhoNJPJ","colab_type":"code","colab":{}},"source":["my_empty_string.isspace()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DdGqVcaUm3ls","colab_type":"code","colab":{}},"source":["blanks = []  # start with an empty list\n","\n","for index,label,review in df.itertuples():  # iterate over the DataFrame\n","    if type(review)==str:            # avoid NaN values\n","        if review.isspace():         # test 'review' for whitespace\n","            blanks.append(index)     # add matching index numbers to the list\n","        \n","print(len(blanks), 'blanks: ', blanks)\n","\n","# these 27 below index positions includes empty spaces"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4TFdWippnINZ","colab_type":"text"},"source":["Next we'll pass our list of index numbers to the **.drop()** method, and set `inplace=True` to make the change permanent."]},{"cell_type":"code","metadata":{"id":"7JuUK6GznIYY","colab_type":"code","colab":{}},"source":["df.drop(blanks, inplace=True)\n","\n","len(df)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wySI5H9PnMSb","colab_type":"text"},"source":["## Take a quick look at the `label` column:"]},{"cell_type":"code","metadata":{"id":"pNM7mbe0nMZN","colab_type":"code","colab":{}},"source":["df['label'].value_counts()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"z9zbWR8CnPsw","colab_type":"text"},"source":["## Split the data into train & test sets:"]},{"cell_type":"code","metadata":{"id":"-8KOiz3wnP2v","colab_type":"code","colab":{}},"source":["from sklearn.model_selection import train_test_split\n","\n","X = df['review']\n","y = df['label']\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4ILB0R9jnSmH","colab_type":"text"},"source":["## Build pipelines to vectorize the data, then train and fit a model\n","Now that we have sets to train and test, we'll develop a selection of pipelines, each with a different model."]},{"cell_type":"code","metadata":{"id":"V0Tqp4hEnSx4","colab_type":"code","colab":{}},"source":["from sklearn.pipeline import Pipeline\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.svm import LinearSVC\n","\n","# Naïve Bayes:\n","text_clf_nb = Pipeline([('tfidf', TfidfVectorizer()),\n","                     ('clf', MultinomialNB()),\n","])\n","\n","# Linear SVC:\n","text_clf_lsvc = Pipeline([('tfidf', TfidfVectorizer()),\n","                     ('clf', LinearSVC()),\n","])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XTFjG4ihnW-i","colab_type":"text"},"source":["## Feed the training data through the first pipeline\n","We'll run naïve Bayes first"]},{"cell_type":"code","metadata":{"id":"F6RREcDynr7B","colab_type":"code","colab":{}},"source":["# creating a dictionary for displaying models' scores:\n","\n","models= {}\n","values= {}\n","\n","scores= dict(zip(models, values))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Fz5q43TPnXHq","colab_type":"code","colab":{}},"source":["text_clf_nb.fit(X_train, y_train)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"88qOJl_ZnYiX","colab_type":"code","colab":{}},"source":["# Form a prediction set\n","predictions = text_clf_nb.predict(X_test) #naive bayes"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pDGIBiTlonh_","colab_type":"code","colab":{}},"source":["df.label.unique()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rkL3ky-xnaT2","colab_type":"code","colab":{}},"source":["# Report the confusion matrix\n","from sklearn import metrics\n","print(metrics.confusion_matrix(y_test,predictions))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Bs3nW_Xkow9x","colab_type":"code","colab":{}},"source":["# You can make the confusion matrix less confusing by adding labels:\n","df = pd.DataFrame(metrics.confusion_matrix(y_test,predictions), index=['negative','positive'], columns=['negative','positive'])\n","df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mtyjAD_jnbXH","colab_type":"code","colab":{}},"source":["# Print a classification report\n","print(metrics.classification_report(y_test,predictions))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"embOlHZ7ncTx","colab_type":"code","colab":{}},"source":["# Print the overall accuracy\n","print(metrics.accuracy_score(y_test,predictions))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UMEIb-xbnxjc","colab_type":"code","colab":{}},"source":["\n","# to add score values in dictionary for the final comparison plot\n","scores[\"Naive Bayes\"]= metrics.accuracy_score(y_test,predictions)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6eaiTd8Cngl5","colab_type":"text"},"source":["Naïve Bayes gave us better-than-average results at 76.4% for classifying reviews as positive or negative based on text alone. Let's see if we can do better."]},{"cell_type":"markdown","metadata":{"id":"127aVcMVn7zM","colab_type":"text"},"source":["## Feed the training data through the second pipeline\n","Next we'll run Linear SVC"]},{"cell_type":"code","metadata":{"id":"a5V1VFAgn78u","colab_type":"code","colab":{}},"source":["text_clf_lsvc.fit(X_train, y_train) #linear SVC"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mXwgkDfNn__O","colab_type":"text"},"source":["## Run predictions and analyze the results (Linear SVC)"]},{"cell_type":"code","metadata":{"id":"mvz1Thj_oAHQ","colab_type":"code","colab":{}},"source":["# Form a prediction set\n","predictions = text_clf_lsvc.predict(X_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gtx6yobdoB8X","colab_type":"code","colab":{}},"source":["# Report the confusion matrix\n","from sklearn import metrics\n","print(metrics.confusion_matrix(y_test,predictions))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ixnbzeq-pSzs","colab_type":"code","colab":{}},"source":["# You can make the confusion matrix less confusing by adding labels:\n","df = pd.DataFrame(metrics.confusion_matrix(y_test,predictions), index=['negative','positive'], columns=['negative','positive'])\n","df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9SxW9jO3oCtl","colab_type":"code","colab":{}},"source":["# Print a classification report\n","print(metrics.classification_report(y_test,predictions))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZaCMsDQ3oDzi","colab_type":"code","colab":{}},"source":["# Print the overall accuracy\n","print(metrics.accuracy_score(y_test,predictions))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"G9SxElAIoFoq","colab_type":"code","colab":{}},"source":["\n","# to add score values in dictionary for the final comparison plot\n","scores[\"Linear SVC\"]= metrics.accuracy_score(y_test,predictions)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"K9_C7xiloMAD","colab_type":"text"},"source":["Not bad! Based on text alone we correctly classified reviews as positive or negative **84.7%** of the time. In an upcoming section we'll try to improve this score even further by performing *sentiment analysis* on the reviews."]},{"cell_type":"markdown","metadata":{"id":"S2wWGuVZoOcr","colab_type":"text"},"source":["# Advanced Topic - Adding Stopwords to CountVectorizer\n","By default, **CountVectorizer** and **TfidfVectorizer** do *not* filter stopwords. However, they offer some optional settings, including passing in your own stopword list.\n","<div class=\"alert alert-info\" style=\"margin: 20px\">CAUTION: There are some [known issues](http://aclweb.org/anthology/W18-2502) using Scikit-learn's built-in stopwords list. Some words that are filtered may in fact aid in classification. In this section we'll pass in our own stopword list, so that we know exactly what's being filtered.</div>"]},{"cell_type":"markdown","metadata":{"id":"8DSwwPakpiV6","colab_type":"text"},"source":["The [CountVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) class accepts the following arguments:\n","> *CountVectorizer(input='content', encoding='utf-8', decode_error='strict', strip_accents=None, lowercase=True, preprocessor=None, tokenizer=None, **stop_words=None**, token_pattern='(?u)\\b\\w\\w+\\b', ngram_range=(1, 1), analyzer='word', max_df=1.0, min_df=1, max_features=None, vocabulary=None, binary=False, dtype=<class 'numpy.int64'>)*\n","\n","[TfidVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html) supports the same arguments and more. Under *stop_words* we have the following options:\n","> stop_words : *string {'english'}, list, or None (default)*\n","\n","That is, we can run `TfidVectorizer(stop_words='english')` to accept scikit-learn's built-in list,<br>\n","or `TfidVectorizer(stop_words=[a, and, the])` to filter these three words. In practice we would assign our list to a variable and pass that in instead."]},{"cell_type":"markdown","metadata":{"id":"dC-BGwoupwnB","colab_type":"text"},"source":["Scikit-learn's built-in list contains 318 stopwords:\n","> <pre>from sklearn.feature_extraction import text\n","> print(text.ENGLISH_STOP_WORDS)</pre>\n","['a', 'about', 'above', 'across', 'after', 'afterwards', 'again', 'against', 'all', 'almost', 'alone', 'along', 'already', 'also', 'although', 'always', 'am', 'among', 'amongst', 'amoungst', 'amount', 'an', 'and', 'another', 'any', 'anyhow', 'anyone', 'anything', 'anyway', 'anywhere', 'are', 'around', 'as', 'at', 'back', 'be', 'became', 'because', 'become', 'becomes', 'becoming', 'been', 'before', 'beforehand', 'behind', 'being', 'below', 'beside', 'besides', 'between', 'beyond', 'bill', 'both', 'bottom', 'but', 'by', 'call', 'can', 'cannot', 'cant', 'co', 'con', 'could', 'couldnt', 'cry', 'de', 'describe', 'detail', 'do', 'done', 'down', 'due', 'during', 'each', 'eg', 'eight', 'either', 'eleven', 'else', 'elsewhere', 'empty', 'enough', 'etc', 'even', 'ever', 'every', 'everyone', 'everything', 'everywhere', 'except', 'few', 'fifteen', 'fifty', 'fill', 'find', 'fire', 'first', 'five', 'for', 'former', 'formerly', 'forty', 'found', 'four', 'from', 'front', 'full', 'further', 'get', 'give', 'go', 'had', 'has', 'hasnt', 'have', 'he', 'hence', 'her', 'here', 'hereafter', 'hereby', 'herein', 'hereupon', 'hers', 'herself', 'him', 'himself', 'his', 'how', 'however', 'hundred', 'i', 'ie', 'if', 'in', 'inc', 'indeed', 'interest', 'into', 'is', 'it', 'its', 'itself', 'keep', 'last', 'latter', 'latterly', 'least', 'less', 'ltd', 'made', 'many', 'may', 'me', 'meanwhile', 'might', 'mill', 'mine', 'more', 'moreover', 'most', 'mostly', 'move', 'much', 'must', 'my', 'myself', 'name', 'namely', 'neither', 'never', 'nevertheless', 'next', 'nine', 'no', 'nobody', 'none', 'noone', 'nor', 'not', 'nothing', 'now', 'nowhere', 'of', 'off', 'often', 'on', 'once', 'one', 'only', 'onto', 'or', 'other', 'others', 'otherwise', 'our', 'ours', 'ourselves', 'out', 'over', 'own', 'part', 'per', 'perhaps', 'please', 'put', 'rather', 're', 'same', 'see', 'seem', 'seemed', 'seeming', 'seems', 'serious', 'several', 'she', 'should', 'show', 'side', 'since', 'sincere', 'six', 'sixty', 'so', 'some', 'somehow', 'someone', 'something', 'sometime', 'sometimes', 'somewhere', 'still', 'such', 'system', 'take', 'ten', 'than', 'that', 'the', 'their', 'them', 'themselves', 'then', 'thence', 'there', 'thereafter', 'thereby', 'therefore', 'therein', 'thereupon', 'these', 'they', 'thick', 'thin', 'third', 'this', 'those', 'though', 'three', 'through', 'throughout', 'thru', 'thus', 'to', 'together', 'too', 'top', 'toward', 'towards', 'twelve', 'twenty', 'two', 'un', 'under', 'until', 'up', 'upon', 'us', 'very', 'via', 'was', 'we', 'well', 'were', 'what', 'whatever', 'when', 'whence', 'whenever', 'where', 'whereafter', 'whereas', 'whereby', 'wherein', 'whereupon', 'wherever', 'whether', 'which', 'while', 'whither', 'who', 'whoever', 'whole', 'whom', 'whose', 'why', 'will', 'with', 'within', 'without', 'would', 'yet', 'you', 'your', 'yours', 'yourself', 'yourselves']\n","\n","However, there are words in this list that may influence a classification of movie reviews. With this in mind, let's trim the list to just 60 words:"]},{"cell_type":"code","metadata":{"id":"TtpIV5sgpwzH","colab_type":"code","colab":{}},"source":["stopwords = ['a', 'about', 'an', 'and', 'are', 'as', 'at', 'be', 'been', 'but', 'by', 'can', \\\n","             'even', 'ever', 'for', 'from', 'get', 'had', 'has', 'have', 'he', 'her', 'hers', 'his', \\\n","             'how', 'i', 'if', 'in', 'into', 'is', 'it', 'its', 'just', 'me', 'my', 'of', 'on', 'or', \\\n","             'see', 'seen', 'she', 'so', 'than', 'that', 'the', 'their', 'there', 'they', 'this', \\\n","             'to', 'was', 'we', 'were', 'what', 'when', 'which', 'who', 'will', 'with', 'you']"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PFnfqHjrp7Ad","colab_type":"text"},"source":["Now let's repeat the process above and see if the removal of stopwords improves or impairs our score."]},{"cell_type":"code","metadata":{"id":"gaXXGevKp7H_","colab_type":"code","colab":{}},"source":["# RUN THIS CELL TO ADD STOPWORDS TO THE LINEAR SVC PIPELINE:\n","text_clf_lsvc2 = Pipeline([('tfidf', TfidfVectorizer(stop_words=stopwords)),\n","                     ('clf', LinearSVC()),\n","])\n","text_clf_lsvc2.fit(X_train, y_train)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QTc79B1zqaIZ","colab_type":"code","colab":{}},"source":["predictions = text_clf_lsvc2.predict(X_test)\n","print(metrics.confusion_matrix(y_test,predictions))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Rl-3zk1Cqbea","colab_type":"code","colab":{}},"source":["print(metrics.classification_report(y_test,predictions))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wRMRd9cfqczK","colab_type":"code","colab":{}},"source":["print(metrics.accuracy_score(y_test,predictions))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"526E2kBNqdpJ","colab_type":"code","colab":{}},"source":["\n","# to add score values in dictionary for the final comparison plot\n","scores[\"Linear SVC_with Stopwords\"]= metrics.accuracy_score(y_test,predictions)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qUIrhjP5qkq-","colab_type":"text"},"source":["Our score didn't change that much. We went from 84.7% without filtering stopwords to 84.4% after adding a stopword filter to our pipeline. Keep in mind that 2000 movie reviews is a relatively small dataset. The real gain from stripping stopwords is improved processing speed; depending on the size of the corpus, it might save hours."]},{"cell_type":"markdown","metadata":{"id":"s5uaCkJOqrBH","colab_type":"text"},"source":["## Feed new data into a trained model\n","Once we've developed a fairly accurate model, it's time to feed new data through it. In this last section we'll write our own review, and see how accurately our model assigns a \"positive\" or \"negative\" label to it."]},{"cell_type":"code","metadata":{"id":"Mjf-PIPVqrIu","colab_type":"code","colab":{}},"source":["myreview = \"A movie I really wanted to love was terrible. \\\n","I'm sure the producers had the best intentions, but the execution was lacking.\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QJpEH7HiqyiG","colab_type":"code","colab":{}},"source":["print(text_clf_nb.predict([myreview]))  # be sure to put \"myreview\" inside square brackets"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"n34pMzZNqz7-","colab_type":"code","colab":{}},"source":["print(text_clf_lsvc.predict([myreview]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"egxmkSLKq1VW","colab_type":"code","colab":{}},"source":["print(text_clf_lsvc2.predict([myreview]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0zPuoseFq5uT","colab_type":"code","colab":{}},"source":["import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","def plot_dict(dictionary):\n","  plt.bar(range(len(dictionary)), list(dictionary.values()), align= \"center\")\n","  plt.xticks(range(len(dictionary)), list(dictionary.keys()))\n","  plt.xlabel(\"Models\")\n","  plt.ylabel(\"Scores\")\n","\n","\n","plot_dict(scores)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jLPxE0IEtBTr","colab_type":"text"},"source":["# Text Classification Assessment\n","\n","This assessment is very much like the Text Classification Project we just completed, and the dataset is very similar.\n","\n","The **moviereviews2.tsv** dataset contains the text of 6000 movie reviews. 3000 are positive, 3000 are negative, and the text has been preprocessed as a tab-delimited file. As before, labels are given as `pos` and `neg`. \n","\n","We've included 20 reviews that contain either `NaN` data, or have strings made up of whitespace.\n","\n","For more information on this dataset visit http://ai.stanford.edu/~amaas/data/sentiment/"]},{"cell_type":"markdown","metadata":{"id":"-xOYlBdxtVLa","colab_type":"text"},"source":["## Task #1: Perform imports and load the dataset into a pandas DataFrame\n","For this exercise you can load the dataset from `'../TextFiles/moviereviews2.tsv'`."]},{"cell_type":"code","metadata":{"id":"ZdzE_DE1tV8j","colab_type":"code","colab":{}},"source":["downloaded = drive.CreateFile({'id':'1B0Nd8l_zgzgz9xFkWe8BmllpnpCqnc_W'}) \n","downloaded.GetContentFile('moviereviews2.tsv') \n","\n","df= pd.read_csv(\"moviereviews2.tsv\", sep='\\t')\n","\n","df.head()\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BZisJ3lFtjxx","colab_type":"code","colab":{}},"source":["df.shape"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nLm9X8h3tpco","colab_type":"text"},"source":["## Task #2: Check for missing values:"]},{"cell_type":"code","metadata":{"id":"8S8KMoHRtpl7","colab_type":"code","colab":{}},"source":["# Check for NaN values:\n","df.isnull().sum()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"m43xRCiStrDW","colab_type":"code","colab":{}},"source":["# Check for whitespace strings (it's OK if there aren't any!):\n","blanks = []  # start with an empty list\n","\n","for index,label,review in df.itertuples():  # iterate over the DataFrame\n","    if type(review)==str:            # avoid NaN values\n","        if review.isspace():         # test 'review' for whitespace\n","            blanks.append(index)     # add matching index numbers to the list\n","        \n","len(blanks)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"R24k5ToDt23z","colab_type":"text"},"source":["## Task #3:  Remove NaN values:"]},{"cell_type":"code","metadata":{"id":"QLmZIybitsue","colab_type":"code","colab":{}},"source":["df.dropna(inplace=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NZsS7Eult7nI","colab_type":"text"},"source":["## Task #4: Take a quick look at the `label` column:"]},{"cell_type":"code","metadata":{"id":"opXD7M4pt5lV","colab_type":"code","colab":{}},"source":["df['label'].value_counts()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"k_F4vREbt_qC","colab_type":"text"},"source":["## Task #5: Split the data into train & test sets:\n","You may use whatever settings you like. To compare your results to the solution notebook, use `test_size=0.33, random_state=42`"]},{"cell_type":"code","metadata":{"id":"PN-WHgp4t9la","colab_type":"code","colab":{}},"source":["from sklearn.model_selection import train_test_split\n","\n","X = df['review']\n","y = df['label']\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"71by6biPuKvm","colab_type":"text"},"source":["## Task #6: Build a pipeline to vectorize the date, then train and fit a model\n","You may use whatever model you like. To compare your results to the solution notebook, use `LinearSVC`."]},{"cell_type":"code","metadata":{"id":"wV-60DWWuBhH","colab_type":"code","colab":{}},"source":["from sklearn.pipeline import Pipeline\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.svm import LinearSVC\n","\n","text_clf = Pipeline([('tfidf', TfidfVectorizer()),\n","                     ('clf', LinearSVC()),\n","])\n","\n","# Feed the training data through the pipeline\n","text_clf.fit(X_train, y_train)  "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"b9uh-X4TuPjh","colab_type":"text"},"source":["## Task #7: Run predictions and analyze the results"]},{"cell_type":"code","metadata":{"id":"oSrXBNsSuMFW","colab_type":"code","colab":{}},"source":["# Form a prediction set\n","predictions = text_clf.predict(X_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lfFj_BBOuQiI","colab_type":"code","colab":{}},"source":["# Report the confusion matrix\n","from sklearn import metrics\n","print(metrics.confusion_matrix(y_test,predictions))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"clUc4S0gucSE","colab_type":"code","colab":{}},"source":["# You can make the confusion matrix less confusing by adding labels:\n","df = pd.DataFrame(metrics.confusion_matrix(y_test,predictions), index=['negative','positive'], columns=['negative','positive'])\n","df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UgdJL4JYuTIT","colab_type":"code","colab":{}},"source":["# Print a classification report\n","print(metrics.classification_report(y_test,predictions))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fU1XxVdcuUC6","colab_type":"code","colab":{}},"source":["# Print the overall accuracy\n","print(metrics.accuracy_score(y_test,predictions))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sayH81hguVF6","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}